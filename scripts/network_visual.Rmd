---
title: "Untitled"
output: html_document
date: "2026-01-04"
---

```{r}
#install.packages("jsonlite")
install.packages("igraph")
install.packages("ggraph")
```


```{r}
library(jsonlite)
library(dplyr)
library(tidyr)

# read in JSON file
json_text <- readLines("/work/pilot/data/processed/finished_label.json", warn = FALSE)
raw_data <- fromJSON(json_text, simplifyVector = FALSE)

cat("Total entries:", length(raw_data), "\n")

# get choices from annotations
get_choices <- function(item) {
  if (!is.null(item$annotations) && length(item$annotations) > 0) {
    if (!is.null(item$annotations[[1]]$result) && length(item$annotations[[1]]$result) > 0) {
      choices <- item$annotations[[1]]$result[[1]]$value$choices
      if (!is.null(choices) && length(choices) > 0) {
        return(unlist(choices))
      }
    }
  }
  return(NA)
}

# convert choices to topic and sentiment
decode_choice <- function(choice_val) {
  val <- as.numeric(choice_val)
  if (is.na(val)) return(list(topic = NA, sentiment = NA))
  
  topic <- ceiling(val / 3)
  sentiment_code <- ((val - 1) %% 3) + 1
  sentiment <- c("positive", "negative", "neutral")[sentiment_code]
  
  return(list(topic = topic, sentiment = sentiment))
}

# get data for each articles
results <- list()

for (i in 1:length(raw_data)) {
  item <- raw_data[[i]]
  file <- item$data$file
  choices <- get_choices(item)
  
  if (!all(is.na(choices)) && length(choices) > 0) {
    #decode each code
    for (choice in choices) {
      decoded <- decode_choice(choice)
      results[[length(results) + 1]] <- data.frame(
        file = file,
        choice_value = choice,
        topic = decoded$topic,
        sentiment = decoded$sentiment,
        stringsAsFactors = FALSE
      )
    }
  }
}

df_long <- bind_rows(results)


# create node label: "topic_X_sentiment"
df_long <- df_long %>%
  mutate(node = paste0("topic_", topic, "_", sentiment))

nodes_per_article <- df_long %>%
  group_by(file) %>%
  summarise(n_nodes = n_distinct(node))

cat("\nArticles by number of nodes:\n")
print(table(nodes_per_article$n_nodes))

# filter only articles with more than 1 node
multi_node_files <- nodes_per_article %>%
  filter(n_nodes > 1) %>%
  pull(file)

df_network <- df_long %>%
  filter(file %in% multi_node_files)

cat("\nArticles with multiple nodes:", length(multi_node_files), "\n")

# edge list
edges <- df_network %>%
  group_by(file) %>%
  arrange(node) %>%
  summarise(
    nodes = list(unique(node)),
    .groups = "drop"
  )

edge_list <- list()
for (i in 1:nrow(edges)) {
  nodes <- unlist(edges$nodes[[i]])
  
  if (length(nodes) > 1) {
    for (j in 1:(length(nodes)-1)) {
      for (k in (j+1):length(nodes)) {
        # sort in alphabetic order to avoid duplicates (A-B and B-A)
        from_node <- min(nodes[j], nodes[k])
        to_node <- max(nodes[j], nodes[k])
        
        edge_list[[length(edge_list) + 1]] <- data.frame(
          from = from_node,
          to = to_node,
          file = edges$file[i],
          stringsAsFactors = FALSE
        )
      }
    }
  }
}

df_edges <- bind_rows(edge_list)

# weight = number of articles
df_edges_weighted <- df_edges %>%
  group_by(from, to) %>%
  summarise(
    weight = n(),
    .groups = "drop"
  ) %>%
  arrange(desc(weight))

cat("\nTotal unique edges:", nrow(df_edges_weighted), "\n")
cat("Total edge occurrences:", nrow(df_edges), "\n")

# node list from attributes
node_list <- df_long %>%
  select(node, topic, sentiment) %>%
  distinct() %>%
  arrange(node)


write.csv(df_edges_weighted, "/work/pilot/data/processed/networks/network_edges_weighted.csv", row.names = FALSE)
write.csv(node_list, "/work/pilot/data/processed/networks/network_nodes.csv", row.names = FALSE)
write.csv(df_network, "/work/pilot/data/processed/networks/articles_with_nodes.csv", row.names = FALSE)

df_edges_full <- df_edges %>%
  arrange(from, to, file)
```


```{r}
write.csv(df_edges_full, "/work/pilot/data/processed/networks/network_edges_full.csv", row.names = FALSE)

cat("\nSaved files:\n")
cat("  - network_edges_weighted.csv (edges with weight = number of articles)\n")
cat("  - network_edges_full.csv (all edges with individual article names)\n")
cat("  - network_nodes.csv (all nodes with topic and sentiment attributes)\n")
cat("  - articles_with_nodes.csv (raw data: which articles contain which nodes)\n")

cat("\n=== SUMMARY ===\n")
cat("Total unique nodes:", nrow(node_list), "\n")
cat("Total unique edges:", nrow(df_edges_weighted), "\n")
cat("Articles with multiple topics/sentiments:", length(multi_node_files), "\n")

cat("\nNode distribution:\n")
node_counts <- df_network %>%
  count(node, sort = TRUE) %>%
  head(15)
print(node_counts)

cat("\nTop 15 strongest connections (by number of articles):\n")
print(head(df_edges_weighted, 15))

cat("\nEdges by sentiment combinations:\n")
sentiment_edges <- df_edges_weighted %>%
  left_join(node_list %>% select(node, sentiment) %>% rename(from = node, sentiment_from = sentiment), by = "from") %>%
  left_join(node_list %>% select(node, sentiment) %>% rename(to = node, sentiment_to = sentiment), by = "to") %>%
  mutate(sentiment_pair = paste(pmin(sentiment_from, sentiment_to), pmax(sentiment_from, sentiment_to), sep = "-")) %>%
  group_by(sentiment_pair) %>%
  summarise(n_edges = n(), total_weight = sum(weight))
print(sentiment_edges)
```

```{r}
############################################################
# KANDIDATTEST TOPIC–SENTIMENT CO-OCCURRENCE NETWORK
# CREATE NODES AND EDGES FILES
############################################################

library(tidyverse)
library(igraph)

# ==========================================================
# 1. LOAD AND CLEAN KANDIDATTEST DATA
# ==========================================================

# Load kandidattest scraped data
kandidat_raw <- read.csv("/work/pilot/data/clean/altinget_answers_playwright_271.csv")


# Define the 10 topics
topic_questions <- c(
  "Q1",  # Topic 1
  "Q5",  # Topic 2
  "Q6",   # Topic 3
  "Q8",  # Topic 4
  "Q17",   # Topic 5
  "Q21",  # Topic 6
  "Q22",   # Topic 7
  "Q23",  # Topic 8
  "Q24",   # Topic 9
  "Q25"   # Topic 10
)

# Select only relevant questions and remove NA rows
kandidat_clean <- kandidat_raw %>%
  select(all_of(topic_questions)) %>%
  drop_na()

cat("Cleaned kandidat responses:", nrow(kandidat_clean), "candidates\n")

# ==========================================================
# 2. RECODE SENTIMENTS (MATCH ARTICLE STRUCTURE)
# ==========================================================

# Recode: -2/-1 → -1 (negative), 0 → 0 (neutral), 1/2 → 1 (positive)
kandidat_sentiment <- kandidat_clean %>%
  mutate(across(everything(), ~case_when(
    . %in% c(-2, -1) ~ -1,
    . == 0 ~ 0,
    . %in% c(1, 2) ~ 1,
    TRUE ~ NA_real_
  )))

# ==========================================================
# 3. CREATE LONG-FORM TABLE (SAME AS ARTICLE STRUCTURE)
# ==========================================================

# Add candidate IDs
kandidat_sentiment <- kandidat_sentiment %>%
  mutate(candidate_id = paste0("kandidat_", row_number()))

# Pivot to long format matching your article structure
df_long <- kandidat_sentiment %>%
  pivot_longer(
    cols = all_of(topic_questions),
    names_to = "question",
    values_to = "opinion"
  ) %>%
  mutate(
    topic = match(question, topic_questions),  # Topic number 1-10
    sentiment = case_when(
      opinion == -1 ~ "negative",
      opinion == 0 ~ "neutral",
      opinion == 1 ~ "positive"
    ),
    node = paste0("topic_", topic, "_", sentiment)
  ) %>%
  select(file = candidate_id, topic, sentiment, opinion, node)

cat("Total topic–sentiment annotations:", nrow(df_long), "\n")

# ==========================================================
# 4. BUILD EDGE LIST (EACH CANDIDATE = FULLY CONNECTED)
# ==========================================================

edge_accumulator <- list()

candidates <- unique(df_long$file)

for (cand in candidates) {
  nodes_cand <- sort(unique(df_long$node[df_long$file == cand]))
  
  # Create all pairwise combinations for this candidate
  if (length(nodes_cand) > 1) {
    comb <- combn(nodes_cand, 2)
    for (j in seq_len(ncol(comb))) {
      edge_accumulator[[length(edge_accumulator) + 1]] <- data.frame(
        from = comb[1, j],
        to   = comb[2, j],
        stringsAsFactors = FALSE
      )
    }
  }
}

edges <- bind_rows(edge_accumulator)

# Weight edges by co-occurrence frequency
edges_weighted <- edges %>%
  count(from, to, name = "weight") %>%
  mutate(weight_norm = weight / max(weight)) %>%
  arrange(desc(weight))

cat("Total unique edges:", nrow(edges_weighted), "\n")

# ==========================================================
# 5. NODE TABLE (SAME STRUCTURE AS ARTICLES)
# ==========================================================

nodes <- df_long %>%
  select(node, topic, sentiment, opinion) %>%
  distinct() %>%
  arrange(topic, sentiment)

cat("Total nodes:", nrow(nodes), "\n")

# ==========================================================
# 6. SAVE FILES (MATCHING YOUR STRUCTURE)
# ==========================================================

# Create directory if it doesn't exist
dir.create("/work/pilot/data/processed/networks", recursive = TRUE, showWarnings = FALSE)

write.csv(
  edges_weighted,
  "/work/pilot/data/processed/networks/kandidat_topic_sentiment_edges.csv",
  row.names = FALSE
)

write.csv(
  nodes,
  "/work/pilot/data/processed/networks/kandidat_topic_sentiment_nodes.csv",
  row.names = FALSE
)

write.csv(
  df_long,
  "/work/pilot/data/processed/networks/kandidat_with_nodes.csv",
  row.names = FALSE
)

cat("✓ Kandidattest network files saved\n")

# ==========================================================
# 7. NETWORK SUMMARY
# ==========================================================

g <- graph_from_data_frame(edges_weighted, vertices = nodes, directed = FALSE)

cat("\nKANDIDATTEST NETWORK SUMMARY\n")
cat("========================================\n")
cat("Nodes:", vcount(g), "\n")
cat("Edges:", ecount(g), "\n")
cat("Density:", edge_density(g), "\n")
cat("Mean edge weight:", mean(E(g)$weight), "\n")
cat("Max edge weight:", max(E(g)$weight), "\n")

# Show top 10 strongest connections
cat("\nTop 10 strongest topic-sentiment connections:\n")
print(head(edges_weighted, 10))

# Show node distribution
cat("\nNode distribution by sentiment:\n")
nodes %>%
  count(sentiment) %>%
  print()

```


```{r}

############################################################
# COMPLETE KANDIDATTEST NETWORK VISUALIZATIONS
# All visualizations in one file
############################################################

library(igraph)
library(ggraph)
library(tidygraph)
library(tidyverse)
library(scales)

# ==========================================================
# LOAD KANDIDATTEST NETWORK DATA
# ==========================================================

edges <- read.csv(
  "/work/pilot/data/processed/networks/kandidat_topic_sentiment_edges.csv",
  stringsAsFactors = FALSE
)

nodes <- read.csv(
  "/work/pilot/data/processed/networks/kandidat_topic_sentiment_nodes.csv",
  stringsAsFactors = FALSE
)

# Build graph object
g <- graph_from_data_frame(
  d = edges,
  vertices = nodes,
  directed = FALSE
)

cat("Kandidattest Network Summary:\n")
cat(" Nodes:", vcount(g), "\n")
cat(" Edges:", ecount(g), "\n")
cat(" Density:", edge_density(g), "\n\n")

# ==========================================================
# VISUAL SETTINGS (USED BY ALL PLOTS)
# ==========================================================

sentiment_colors <- c(
  "negative" = "#E74C3C",
  "neutral"  = "#95A5A6",
  "positive" = "#2ECC71"
)

# Node size = frequency
node_freq <- nodes %>%
  count(node, name = "freq")

V(g)$freq <- node_freq$freq[match(V(g)$name, node_freq$node)]

# ==========================================================
# VISUALIZATION 1: FORCE-DIRECTED NETWORK
# ==========================================================

set.seed(123)

p1 <- ggraph(g, layout = "fr") +
  geom_edge_link(
    aes(width = weight_norm, alpha = weight_norm),
    color = "grey60"
  ) +
  geom_node_point(
    aes(
      color = sentiment,
      size = freq
    )
  ) +
  geom_node_text(
    aes(label = paste0("T", topic)),
    size = 3,
    color = "black",
    repel = TRUE
  ) +
  scale_color_manual(values = sentiment_colors) +
  scale_edge_width(range = c(0.3, 3)) +
  scale_edge_alpha(range = c(0.2, 0.8)) +
  scale_size_continuous(range = c(3, 10)) +
  theme_graph() +
  labs(
    title = "Kandidattest Topic–Sentiment Co-occurrence Network",
    subtitle = "Edges = co-occurrence across candidates (normalized)",
    color = "Sentiment",
    size = "Candidate frequency"
  ) +
  theme(legend.position = "bottom")

#ggsave(
#  "/work/pilot/data/processed/networks/kandidat_network_force.png",
#  p1,
#  width = 12,
#  height = 10,
#  dpi = 300
#)

cat("✓ Force-directed network saved\n")

# ==========================================================
# VISUALIZATION 2: CIRCULAR LAYOUT
# ==========================================================

p2 <- ggraph(g, layout = "linear", circular = TRUE) +
  geom_edge_arc(
    aes(width = weight_norm, alpha = weight_norm),
    color = "grey60"
  ) +
  geom_node_point(
    aes(color = sentiment),
    size = 6
  ) +
  geom_node_text(
    aes(label = paste0("T", topic)),
    size = 2.5,
    vjust = 1.5
  ) +
  scale_color_manual(values = sentiment_colors) +
  scale_edge_width(range = c(0.2, 2)) +
  scale_edge_alpha(range = c(0.2, 0.7)) +
  theme_graph() +
  labs(
    title = "Kandidattest Topic–Sentiment Network (Circular)",
    color = "Sentiment"
  ) +
  theme(legend.position = "bottom")

#ggsave(
#  "/work/pilot/data/processed/networks/kandidat_network_circular.png",
#  p2,
#  width = 12,
#  height = 12,
#  dpi = 300
#)

cat("✓ Circular network saved\n")

# ==========================================================
# VISUALIZATION 3: COMMUNITIES (IDEOLOGICAL BLOCS)
# ==========================================================

communities <- cluster_louvain(g)
V(g)$community <- membership(communities)

cat("Number of communities detected:", max(V(g)$community), "\n\n")

p3 <- ggraph(g, layout = "fr") +
  geom_edge_link(
    aes(width = weight_norm),
    alpha = 0.3,
    color = "grey70"
  ) +
  geom_node_point(
    aes(
      color = sentiment,
      shape = as.factor(community)
    ),
    size = 6
  ) +
  geom_node_text(
    aes(label = paste0("T", topic)),
    size = 3,
    repel = TRUE
  ) +
  scale_color_manual(values = sentiment_colors) +
  scale_edge_width(range = c(0.3, 3)) +
  theme_graph() +
  labs(
    title = "Kandidattest Topic–Sentiment Communities",
    subtitle = "Ideological clusters in candidate opinion structure",
    color = "Sentiment",
    shape = "Structural cluster"
  ) +
  theme(legend.position = "bottom")

#ggsave(
#  "/work/pilot/data/processed/networks/kandidat_network_communities.png",
#  p3,
#  width = 12,
#  height = 10,
#  dpi = 300
#)

cat("✓ Community network saved\n")

# ==========================================================
# VISUALIZATION 4: FULL HEATMAP (30x30)
# ==========================================================

# Keep strong connections
edges_plot <- edges %>%
  filter(weight_norm > 0.05)

# Create symmetric matrix
matrix_df <- edges_plot %>%
  select(from, to, weight_norm) %>%
  bind_rows(
    edges_plot %>%
      transmute(from = to, to = from, weight_norm = weight_norm)
  )

# Add diagonal
all_nodes <- unique(nodes$node)
diagonal_df <- data.frame(
  from = all_nodes,
  to = all_nodes,
  weight_norm = 1.0
)

matrix_df <- bind_rows(matrix_df, diagonal_df) %>%
  distinct(from, to, .keep_all = TRUE)

# Order nodes
sentiment_order <- c("negative", "neutral", "positive")

node_order <- nodes %>%
  arrange(topic, match(sentiment, sentiment_order)) %>%
  pull(node)

matrix_df <- matrix_df %>%
  mutate(
    from = factor(from, levels = node_order),
    to   = factor(to,   levels = node_order)
  ) %>%
  filter(!is.na(from) & !is.na(to))

# Plot heatmap
p4 <- ggplot(matrix_df, aes(x = from, y = to, fill = weight_norm)) +
  geom_tile(color = "white", linewidth = 0.2) +
  scale_fill_gradient2(
    low = "#3B4CC0",
    mid = "#F7F7F7", 
    high = "#B40426",
    midpoint = 0.5,
    name = "Alignment\nstrength",
    limits = c(0, 1),
    breaks = c(0, 0.25, 0.5, 0.75, 1.0)
  ) +
  coord_fixed() +
  theme_minimal(base_size = 10) +
  theme(
    axis.text.x = element_text(
      angle = 90,
      vjust = 0.5,
      hjust = 1,
      size = 7
    ),
    axis.text.y = element_text(size = 7),
    axis.title = element_blank(),
    panel.grid = element_blank()
  ) +
  labs(
    title = "Kandidattest Topic–Sentiment Co-occurrence Matrix",
    subtitle = "Normalized symmetric co-occurrence across candidates"
  )

#ggsave(
#  "/work/pilot/data/processed/networks/kandidat_network_heatmap.png",
#  p4,
#  width = 14,
#  height = 12,
#  dpi = 300
#)

cat(" Full heatmap saved\n")

# ==========================================================
# VISUALIZATION 5: PRETTY NETWORK (PUBLICATION-READY)
# ==========================================================

# Filter for cleaner visualization
edges_clean <- edges %>%
  filter(weight_norm >= 0.15)

g_clean <- graph_from_data_frame(
  d = edges_clean,
  vertices = nodes,
  directed = FALSE
)

V(g_clean)$freq <- node_freq$freq[match(V(g_clean)$name, node_freq$node)]

sentiment_colors_clean <- c(
  "negative" = "#D55E00",
  "neutral"  = "#999999",
  "positive" = "#009E73"
)

set.seed(42)

p5 <- ggraph(g_clean, layout = "stress") +
  geom_edge_link(
    aes(
      width = weight_norm,
      alpha = weight_norm
    ),
    colour = "grey50",
    show.legend = FALSE
  ) +
  geom_node_point(
    aes(
      color = sentiment,
      size = freq
    ),
    alpha = 0.9
  ) +
  geom_node_text(
    aes(label = paste0("T", topic)),
    size = 3.5,
    repel = TRUE,
    segment.alpha = 0.3
  ) +
  scale_color_manual(values = sentiment_colors_clean) +
  scale_edge_width(range = c(0.4, 3)) +
  scale_edge_alpha(range = c(0.2, 0.9)) +
  scale_size_continuous(range = c(4, 10)) +
  theme_graph(base_family = "sans") +
  labs(
    title = "Kandidattest Topic–Sentiment Co-occurrence Network",
    subtitle = "Ideological structure of candidate opinions",
    color = "Sentiment",
    size = "Candidate frequency"
  ) +
  theme(
    legend.position = "bottom",
    plot.title = element_text(face = "bold")
  )

#ggsave(
#  "/work/pilot/data/processed/networks/kandidat_network_pretty.png",
#  p5,
#  width = 12,
#  height = 10,
#  dpi = 300
#)

cat(" Pretty network saved\n")

# ==========================================================
# VISUALIZATION 6: TOPIC-LEVEL HEATMAP (10x10, CLEANER)
# ==========================================================

# Add topic info to edges
edges_topics <- edges %>%
  left_join(
    nodes

print(p1)
print(p2)
print(p3)
print(p4)
print(p5)
```

